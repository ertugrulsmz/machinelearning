{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm-hidden-cell-keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgwDe6lcRmr1"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import LSTM, Bidirectional\n",
        "from numpy import array\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts97p-x8I7Na"
      },
      "source": [
        "### Return sequence false -->  lstm(4) just last state (batch_size,hidden)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqPoipQRedSa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fbde93c-0273-4c03-eae7-f42af947d4f4"
      },
      "source": [
        "# define model\n",
        "inputs1 = Input(shape=(3, 3))\n",
        "lstm1 = LSTM(4)(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=lstm1)\n",
        "# define input data\n",
        "data = array([[0.1,0.2,0.99], [0.2,0.5,0.1], [0.3,0.9,0.65]]).reshape((1,3,3))\n",
        "# make and show prediction\n",
        "print(model.predict(data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.13260265  0.27385584 -0.24074206  0.2737454 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gcvaww1LJg7s"
      },
      "source": [
        "### Return sequence true -->  lstm(4) just last state (batch_size,seq_len,hidden)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s5VohOEIp_R",
        "outputId": "1614f36a-9d65-42ac-b2d1-74115e482236"
      },
      "source": [
        "inputs1 = Input(shape=(3, 3))\n",
        "lstm1 = LSTM(4, return_sequences=True)(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=lstm1)\n",
        "# define input data\n",
        "data = array([[0.1,0.2,0.99], [0.2,0.5,0.1], [0.3,0.9,0.65]]).reshape((1,3,3))\n",
        "# make and show prediction\n",
        "print(model.predict(data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f726a597c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[[ 0.0141136   0.06267215  0.05431435 -0.13560493]\n",
            "  [-0.02658494 -0.01102044  0.04490502 -0.04736639]\n",
            "  [-0.06545106 -0.07161186  0.06655654 -0.02885797]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM2_FmOEJyjB"
      },
      "source": [
        "#### Return state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqKpXlmALE4X"
      },
      "source": [
        "#### Return state = true, \n",
        "#### out = (batch_size, hidden)\n",
        "#### hidden = (batch_size,hidden) -- out same\n",
        "#### cell = (batch_size,hidden)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGRbS24zJZjR",
        "outputId": "7d36f8ad-6236-4c63-8c9a-05bc7c8a9a73"
      },
      "source": [
        "inputs1 = Input(shape=(3, 3))\n",
        "lstm1 = LSTM(4, return_state=True)(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=lstm1)\n",
        "# define input data\n",
        "data = array([[0.1,0.2,0.99], [0.2,0.5,0.1], [0.3,0.9,0.65]]).reshape((1,3,3))\n",
        "# make and show prediction\n",
        "out, hidden, cell = (model.predict(data))\n",
        "\n",
        "print(\"out : \",out)\n",
        "print(\"hidden : \",hidden)\n",
        "print(\"cell : \",cell)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f726ce7bcb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "out :  [[ 0.15033197 -0.06739371 -0.03980701 -0.27022973]]\n",
            "hidden :  [[ 0.15033197 -0.06739371 -0.03980701 -0.27022973]]\n",
            "cell :  [[ 0.25727272 -0.12203526 -0.09423355 -0.5904674 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXokkKqwLqtD"
      },
      "source": [
        "#### Return state = true, \n",
        "#### out = (batch_size, seq, hidden)\n",
        "#### hidden = (batch_size,hidden) -- out[-1] same\n",
        "#### cell = (batch_size,hidden)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKeGzedQK-6Z",
        "outputId": "bfc6bcb7-220b-41f7-c39d-1c9b047ef47d"
      },
      "source": [
        "inputs1 = Input(shape=(3, 3))\n",
        "lstm1 = LSTM(4, return_state=True, return_sequences=True)(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=lstm1)\n",
        "# define input data\n",
        "data = array([[0.1,0.2,0.99], [0.2,0.5,0.1], [0.3,0.9,0.65]]).reshape((1,3,3))\n",
        "# make and show prediction\n",
        "out, hidden, cell = (model.predict(data))\n",
        "\n",
        "print(\"out : \",out)\n",
        "print(\"hidden : \",hidden)\n",
        "print(\"cell : \",cell)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7272399830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "out :  [[[-0.09043669  0.15893129 -0.00874605  0.09069443]\n",
            "  [-0.11746418  0.13571349 -0.01326715  0.03862947]\n",
            "  [-0.15278938  0.2230941  -0.01352364  0.04636482]]]\n",
            "hidden :  [[-0.15278938  0.2230941  -0.01352364  0.04636482]]\n",
            "cell :  [[-0.38634565  0.44384152 -0.03899081  0.11062123]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLttUcPrEMbJ"
      },
      "source": [
        "### Bidirectional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyhZaJHBLkhR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58966f1d-29fb-4de2-c067-bc704f5e64d8"
      },
      "source": [
        "inputs1 = Input(shape=(3, 3))\n",
        "lstm1 = Bidirectional(LSTM(4, return_state=True, return_sequences=True))(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=lstm1)\n",
        "# define input data\n",
        "data = array([[0.1,0.2,0.99], [0.2,0.5,0.1], [0.3,0.9,0.65]]).reshape((1,3,3))\n",
        "# make and show prediction\n",
        "a = (model.predict(data))\n",
        "\"\"\"\n",
        "print(\"out : \",out)\n",
        "print(\"hidden : \",hidden)\n",
        "print(\"cell : \",cell)\n",
        "\"\"\"\n",
        "print(\"a[0]\",a[0].shape)\n",
        "a\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a[0] (1, 3, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[[-0.05059863,  0.04636485,  0.05786786,  0.07078998,\n",
              "           0.01716897,  0.23533122,  0.18849233, -0.0549852 ],\n",
              "         [ 0.01286594,  0.08022677,  0.05811954, -0.00762515,\n",
              "          -0.07412362,  0.16171779,  0.11127771,  0.03534358],\n",
              "         [ 0.04418893,  0.13021913,  0.0708093 , -0.03784038,\n",
              "          -0.02641132,  0.12697817,  0.10407488,  0.01650312]]],\n",
              "       dtype=float32),\n",
              " array([[ 0.04418893,  0.13021913,  0.0708093 , -0.03784038]],\n",
              "       dtype=float32),\n",
              " array([[ 0.11788242,  0.2906269 ,  0.18503165, -0.08274363]],\n",
              "       dtype=float32),\n",
              " array([[ 0.01716897,  0.23533122,  0.18849233, -0.0549852 ]],\n",
              "       dtype=float32),\n",
              " array([[ 0.04637791,  0.5268264 ,  0.49135128, -0.1387937 ]],\n",
              "       dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf43qdBYEmqk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}