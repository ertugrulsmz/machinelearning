{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transferLearning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxIs5k6CK3Zk"
      },
      "source": [
        "### Based on PyTorch's transfer learning tutorial: https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html ###\n",
        "\n",
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "import shutil  \n",
        "import re  \n",
        "\n",
        "### Data Preprocessing ###\n",
        "\n",
        "base_dir = \"/PetImages/\"  \n",
        "  \n",
        "# create training folder  \n",
        "  \n",
        "files = os.listdir(base_dir)  \n",
        "  \n",
        "# Moves all training cat images to cats folder, training dog images to dogs folder  \n",
        "def train_maker(name):  \n",
        "  \n",
        "  train_dir = f\"{base_dir}/train/{name}\"  \n",
        "    \n",
        "  for f in files:  \n",
        "        search_object = re.search(name, f)  \n",
        "        if search_object:  \n",
        "          shutil.move(f'{base_dir}/{name}', train_dir)  \n",
        "  \n",
        "train_maker(\"Cat\")  \n",
        "train_maker(\"Dog\")  \n",
        "  \n",
        "# make the validation directories  \n",
        "try:  \n",
        "    os.makedirs(\"val/Cat\")  \n",
        "    os.makedirs(\"val/Dog\")  \n",
        "except OSError:  \n",
        "    print (\"Creation of the directory %s failed\")  \n",
        "else:  \n",
        "    print (\"Successfully created the directory %s \")  \n",
        "  \n",
        "# create validation folder  \n",
        "  \n",
        "cat_train = base_dir + \"train/Cat/\"  \n",
        "cat_val = base_dir + \"val/Cat/\"  \n",
        "dog_train = base_dir + \"train/Dog/\"  \n",
        "dog_val = base_dir + \"val/Dog/\"  \n",
        "  \n",
        "cat_files = os.listdir(cat_train)  \n",
        "dog_files = os.listdir(dog_train)  \n",
        "\n",
        "# This will put 1000 images from the two training folders\n",
        "# into their respective validation folders\n",
        "\n",
        "for f in cat_files:  \n",
        "    validationCatsSearchObj = re.search(\"5\\d\\d\\d\", f)  \n",
        "    if validationCatsSearchObj:  \n",
        "        shutil.move(f'{cat_train}/{f}', cat_val)  \n",
        "  \n",
        "for f in dog_files:  \n",
        "    validationDogsSearchObj = re.search(\"5\\d\\d\\d\", f)  \n",
        "    if validationDogtsSearchObj:  \n",
        "        shutil.move(f'{dog_train}/{f}', dog_val)\n",
        "\n",
        "### End Preprocessing ###\n",
        "\n",
        "# This main wrapper is only necessary if on Windows\n",
        "\n",
        "def main():\n",
        "\n",
        "    # Make transforms and use data loaders\n",
        "\n",
        "    # Will be using these values a lot, so make them variables\n",
        "    \n",
        "    mean_nums = [0.485, 0.456, 0.406]\n",
        "    std_nums = [0.229, 0.224, 0.225]\n",
        "\n",
        "    chosen_transforms = {'train': transforms.Compose([\n",
        "            transforms.RandomResizedCrop(size=256),\n",
        "            transforms.RandomRotation(degrees=15),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean_nums, std_nums)\n",
        "        ])\n",
        "    , 'val': transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean_nums, std_nums)\n",
        "    ]),\n",
        "    }\n",
        "\n",
        "    # Set the directory for the data\n",
        "\n",
        "    data_dir = '/PetImages/'\n",
        "\n",
        "    # Use the image folder function to create datasets.\n",
        "\n",
        "    chosen_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                              chosen_transforms[x])\n",
        "                      for x in ['train', 'val']}\n",
        "\n",
        "\n",
        "    # Make iterables with the dataloaders.\n",
        "\n",
        "    dataloaders = {x: torch.utils.data.DataLoader(chosen_datasets[x], batch_size=4,\n",
        "                                                 shuffle=True, num_workers=4)\n",
        "                  for x in ['train', 'val']}\n",
        "\n",
        "\n",
        "    dataset_sizes = {x: len(chosen_datasets[x]) for x in ['train', 'val']}\n",
        "    class_names = chosen_datasets['train'].classes\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # visualize some images\n",
        "\n",
        "    def imshow(inp, title=None):\n",
        "        inp = inp.numpy().transpose((1, 2, 0))\n",
        "        mean = np.array([mean_nums])\n",
        "        std = np.array([std_nums])\n",
        "        inp = std * inp + mean\n",
        "        inp = np.clip(inp, 0, 1)\n",
        "        plt.imshow(inp)\n",
        "        if title is not None:\n",
        "            plt.title(title)\n",
        "        plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "    # Going to grab some of the training data to visualize\n",
        "    \n",
        "    inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "    # Make a grid from batch\n",
        "    out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "    imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "    # Setting up the model\n",
        "    # We need to load in pretrained and reset final fully connected\n",
        "\n",
        "    res_mod = models.resnet34(pretrained=True)\n",
        "    for param in res_mod.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # the parameters of imported models are set to requires_grad=True by default\n",
        "\n",
        "    num_ftrs = res_mod.fc.in_features\n",
        "    res_mod.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    res_mod = res_mod.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Here's the main change, instead of all paramters being optimized\n",
        "    # Only the params of the final layers are being optmized\n",
        "    \n",
        "    optimizer_ft = optim.SGD(res_mod.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "    \n",
        "    # How you can selectively unfreeze layers...\n",
        "    # in order to selectively unfreeze layers, need to specify the layers that require grad\n",
        "    \n",
        "    ## for param in res_mod.parameters():\n",
        "    ##    param.requires_grad = False\n",
        "\n",
        "    ## for name, child in res_mod.named_children():\n",
        "    ##    if name in ['layer3', 'layer4']:\n",
        "    ##        print(name + 'has been unfrozen.')\n",
        "    ##        for param in child.parameters():\n",
        "    ##            param.requires_grad = True\n",
        "    ##    else:\n",
        "    ##        for param in child.parameters():\n",
        "    ##            param.requires_grad = False\n",
        "\n",
        "    # also need to update optimization function\n",
        "    # only optimize those that require grad\n",
        "    \n",
        "    ## optimizer_conv = torch.optim.SGD(filter(lambda x: x.requires_grad, res_mod.parameters()), lr=0.001, momentum=0.9)\n",
        "    \n",
        "\n",
        "    def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
        "        since = time.time()\n",
        "\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        best_acc = 0.0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "            print('-' * 10)\n",
        "\n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()\n",
        "                    model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "                current_loss = 0.0\n",
        "                current_corrects = 0\n",
        "\n",
        "                # Here's where the training happens\n",
        "                print('Iterating through data...')\n",
        "\n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    #  We need to zero the gradients, don't forget it\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # Time to carry out the forward training poss\n",
        "                    # We only need to log the loss stats if we are in training phase\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        outputs = model(inputs)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                        # backward + optimize only if in training phase\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # We want variables to hold the loss statistics\n",
        "                    current_loss += loss.item() * inputs.size(0)\n",
        "                    current_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "                epoch_loss = current_loss / dataset_sizes[phase]\n",
        "                epoch_acc = current_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                    phase, epoch_loss, epoch_acc))\n",
        "\n",
        "                # Make a copy of the model if the accuracy on the validation set has improved\n",
        "                if phase == 'val' and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            print()\n",
        "\n",
        "        time_since = time.time() - since\n",
        "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "            time_since // 60, time_since % 60))\n",
        "        print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "        # Now we'll load in the best model weights and return it\n",
        "        model.load_state_dict(best_model_wts)\n",
        "        return model\n",
        "\n",
        "\n",
        "    def visualize_model(model, num_images=6):\n",
        "        was_training = model.training\n",
        "        model.eval()\n",
        "        images_handeled = 0\n",
        "        fig = plt.figure()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                for j in range(inputs.size()[0]):\n",
        "                    images_handeled += 1\n",
        "                    ax = plt.subplot(num_images//2, 2, images_handeled)\n",
        "                    ax.axis('off')\n",
        "                    ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                    imshow(inputs.cpu().data[j])\n",
        "\n",
        "                    if images_handeled == num_images:\n",
        "                        model.train(mode=was_training)\n",
        "                        return\n",
        "            model.train(mode=was_training)\n",
        "\n",
        "    base_model = train_model(res_mod, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=10)\n",
        "    visualize_model(base_model)\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}