{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imdb.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "09syCd-j_kWS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fd6e9943-05a6-4496-8120-eeba2590329f"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "# !pip install -q tensorflow-datasets"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcVJjULy_lS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "imdb, info = tfds.load(\"imdb_reviews\", with_info=True, as_supervised=True)\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrh7AWPIAwYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "train_data, test_data = imdb['train'], imdb['test']\n",
        "\n",
        "training_sentences = []\n",
        "training_labels = []\n",
        "\n",
        "testing_sentences = []\n",
        "testing_labels = []\n",
        "\n",
        "# str(s.tonumpy()) is needed in Python3 instead of just s.numpy()\n",
        "for s,l in train_data:\n",
        "  training_sentences.append(s.numpy().decode('utf8'))\n",
        "  training_labels.append(l.numpy())\n",
        "  \n",
        "for s,l in test_data:\n",
        "  testing_sentences.append(s.numpy().decode('utf8'))\n",
        "  testing_labels.append(l.numpy())\n",
        "  \n",
        "training_labels_final = np.array(training_labels)\n",
        "testing_labels_final = np.array(testing_labels)\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSGFboIZA3rB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1dd9280-5606-496f-8332-9eb2325b6f07"
      },
      "source": [
        "train_data"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: ((), ()), types: (tf.string, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WV_jPmh_oss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 10000\n",
        "embedding_dim = 16\n",
        "max_length = 120\n",
        "trunc_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(testing_sequences,maxlen=max_length)\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL-SIGEeCTEf",
        "colab_type": "text"
      },
      "source": [
        "## Note : Word index starts from 1 which is oov_token. When padded is done, if text is not long enough, 0 will be added to the beginning/end array. So in decode_review function, it will return '*' when it see 0, since '0' has no value in reverse_word_index dictionary.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8eDnilABLQR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "77119632-bcb5-4866-fcdf-d749a8781e46"
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    print(\"text is \",text)\n",
        "    return ' '.join([reverse_word_index.get(i, '*') for i in text])\n",
        "\n",
        "print( \"OOV Means word not in tokenizer. * represents pad that is added later.\")\n",
        "print()\n",
        "print(decode_review(padded[3]))\n",
        "print(training_sentences[3])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OOV Means word not in tokenizer. * represents pad that is added later.\n",
            "\n",
            "text is  [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0   12    7    2  241    5   20   16    4 8776 2707 2653\n",
            "   52    2  358    5    2  180   68  138 1401   17   92  203  968   15\n",
            "   23    1   81    4  192 3109 3037    3    1   16    4  376    5  632\n",
            "  387  352   37 6355    3 5559 1928   15  208 8596 3433    2  112  365\n",
            "   48   24   55    1    6 1657   55 1818 4312   41    4 2263    3 1908\n",
            "    1  141  160  780  111   31   92  116    4  221   20    9  173  279\n",
            "    3   29   13 1012    2 2814   10 1985]\n",
            "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * this is the kind of film for a snowy sunday afternoon when the rest of the world can go ahead with its own business as you <OOV> into a big arm chair and <OOV> for a couple of hours wonderful performances from cher and nicolas cage as always gently row the plot along there are no <OOV> to cross no dangerous waters just a warm and witty <OOV> through new york life at its best a family film in every sense and one that deserves the praise it received\n",
            "This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful performances from Cher and Nicolas Cage (as always) gently row the plot along. There are no rapids to cross, no dangerous waters, just a warm and witty paddle through New York life at its best. A family film in every sense and one that deserves the praise it received.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk_SiIIcAr9H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "b074bb15-c591-468e-ea1b-40747d697f35"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(6, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 120, 16)           160000    \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1920)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 6)                 11526     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 171,533\n",
            "Trainable params: 171,533\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvqFm92-RdL1",
        "colab_type": "text"
      },
      "source": [
        "## Embedding layer is basically lookup table. Param indicates there are 1000(vocabsize) row with 16 ( embedding size) column in look up table.\n",
        "As every sentence limited with max 120 word. it can 120*16 as a output shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_fsCSZARHO_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "ca97985a-1405-4e35-82c9-80422bcc198e"
      },
      "source": [
        "num_epochs = 10\n",
        "model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.4889 - accuracy: 0.7444 - val_loss: 0.3448 - val_accuracy: 0.8493\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.2323 - accuracy: 0.9127 - val_loss: 0.3744 - val_accuracy: 0.8375\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0846 - accuracy: 0.9781 - val_loss: 0.4627 - val_accuracy: 0.8243\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0218 - accuracy: 0.9972 - val_loss: 0.5259 - val_accuracy: 0.8238\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0056 - accuracy: 0.9996 - val_loss: 0.5872 - val_accuracy: 0.8253\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6488 - val_accuracy: 0.8228\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 8.8129e-04 - accuracy: 1.0000 - val_loss: 0.6814 - val_accuracy: 0.8258\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 4.5174e-04 - accuracy: 1.0000 - val_loss: 0.7156 - val_accuracy: 0.8264\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 2.6354e-04 - accuracy: 1.0000 - val_loss: 0.7541 - val_accuracy: 0.8258\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.5902e-04 - accuracy: 1.0000 - val_loss: 0.7907 - val_accuracy: 0.8258\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f57466ca2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp7Q2IvASclg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e90e763-9ad0-4c1b-e9b4-942047be6138"
      },
      "source": [
        "e = model.layers[0]\n",
        "weights = e.get_weights()[0]\n",
        "print(weights.shape) # shape: (vocab_size, embedding_dim)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ED6NLEBSqId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "\n",
        "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "for word_num in range(1, vocab_size):\n",
        "  word = reverse_word_index[word_num]\n",
        "  embeddings = weights[word_num]\n",
        "  out_m.write(word + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf_cf_ksSuBu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1c0e6b55-3a75-4806-c120-a38201130803"
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download('vecs.tsv')\n",
        "  files.download('meta.tsv')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_ca796866-83fb-4737-8c38-2daaeb7922f6\", \"vecs.tsv\", 1909728)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_8d52ab65-c75d-44a3-a16e-155bf017f6a1\", \"meta.tsv\", 76186)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XETTCTMxXQi3",
        "colab_type": "text"
      },
      "source": [
        "## Prediction Part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5P3pWWDSvw6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "31dca651-5ecd-4427-b1f3-d1509676f259"
      },
      "source": [
        "print(training_sentences[5])\n",
        "\n",
        "sentence1 = training_sentences[5]\n",
        "sequence1 = tokenizer.texts_to_sequences([sentence])\n",
        "print(sequence1)\n",
        "\n",
        "pad1 = pad_sequences(sequence1,maxlen=max_length, truncating=trunc_type)\n",
        "\n",
        "\n",
        "a = model.predict(pad1)\n",
        "print(a)\n",
        "print(a>0.5)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a film which should be seen by anybody interested in, effected by, or suffering from an eating disorder. It is an amazingly accurate and sensitive portrayal of bulimia in a teenage girl, its causes and its symptoms. The girl is played by one of the most brilliant young actresses working in cinema today, Alison Lohman, who was later so spectacular in 'Where the Truth Lies'. I would recommend that this film be shown in all schools, as you will never see a better on this subject. Alison Lohman is absolutely outstanding, and one marvels at her ability to convey the anguish of a girl suffering from this compulsive disorder. If barometers tell us the air pressure, Alison Lohman tells us the emotional pressure with the same degree of accuracy. Her emotional range is so precise, each scene could be measured microscopically for its gradations of trauma, on a scale of rising hysteria and desperation which reaches unbearable intensity. Mare Winningham is the perfect choice to play her mother, and does so with immense sympathy and a range of emotions just as finely tuned as Lohman's. Together, they make a pair of sensitive emotional oscillators vibrating in resonance with one another. This film is really an astonishing achievement, and director Katt Shea should be proud of it. The only reason for not seeing it is if you are not interested in people. But even if you like nature films best, this is after all animal behaviour at the sharp edge. Bulimia is an extreme version of how a tormented soul can destroy her own body in a frenzy of despair. And if we don't sympathise with people suffering from the depths of despair, then we are dead inside.\n",
            "[[11, 64, 102, 12, 7, 478, 1200]]\n",
            "[[0.90550506]]\n",
            "[[ True]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Csk15zCMTY6c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "3029b52a-4e65-466a-bc74-d288d27b89a3"
      },
      "source": [
        "#My Test Set by just an input\n",
        "mytestdata = np.array([\"It was great, I liked it.\",\"I hate it , disgusting!\",\"Shit \",\"best great good movie\",\"great best movie, amazing\"])\n",
        "anothersequences = tokenizer.texts_to_sequences(mytestdata)\n",
        "padded2 = pad_sequences(anothersequences,maxlen=120, truncating=trunc_type)\n",
        "another_prediction = model.predict(padded2)\n",
        "\n",
        "#My Test Set results\n",
        "another_prediction_result = another_prediction > 0.5\n",
        "print(another_prediction)\n",
        "print(another_prediction_result)\n",
        "\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.8459643 ]\n",
            " [0.00949743]\n",
            " [0.09955162]\n",
            " [0.89622116]\n",
            " [0.9958124 ]]\n",
            "[[ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp7KJ4suVnst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}